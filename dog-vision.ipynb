{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-18T05:16:28.129622Z","iopub.execute_input":"2021-11-18T05:16:28.130009Z","iopub.status.idle":"2021-11-18T05:16:41.46786Z","shell.execute_reply.started":"2021-11-18T05:16:28.129966Z","shell.execute_reply":"2021-11-18T05:16:41.467188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:16:41.47009Z","iopub.execute_input":"2021-11-18T05:16:41.470351Z","iopub.status.idle":"2021-11-18T05:16:41.473507Z","shell.execute_reply.started":"2021-11-18T05:16:41.470315Z","shell.execute_reply":"2021-11-18T05:16:41.47283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = pd.read_csv(\"../input/dog-breed-identification/labels.csv\")\nlabels.columns\nlabels","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:16:41.474591Z","iopub.execute_input":"2021-11-18T05:16:41.474869Z","iopub.status.idle":"2021-11-18T05:16:41.527396Z","shell.execute_reply.started":"2021-11-18T05:16:41.474834Z","shell.execute_reply":"2021-11-18T05:16:41.526583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# End-to-End multi-class Dog breed classification\n\nThis notebook builds an end-to end multi-class image classifier using TensorFlow 2.0 and Tensorflow Hub\n\n## 1.Problem\n\nIdentifying the breed of a dog given an image of a dog.\n\nWhen I'm sitting at the cafe and I take a photo of a dog, I want to know what breed of dog it is.\n\n## 2.Data\n\nThe data we're using from https://www.kaggle.com/c/dog-breed-identification/data\n\n## 3. Evaluation\n \nThe evaluation is a file with prediction probabilities for each dog breed of each test image\nhttps://www.kaggle.com/c/dog-breed-identification/overview/evaluation\n\n## 4. Features\n\nSome information about the data:\n* we're dealing images (unstructured data) so it's probably best we use deep learning/ transfer learning. \n* There are 120 breeds of dogs(this means there are 120 different classes).\n* There are around 10,000+ images in the training set(these images have labels)\n* There are around 10,000+ images in the test set (these images have no labels, because we'll want to predict them).\n\n\n\n","metadata":{}},{"cell_type":"markdown","source":"## Get our workspace ready\n\n1. Import TensorFlow 2.x\n2. Import TensorFlow Hub\n3. Make sure we're using a GPU","metadata":{}},{"cell_type":"code","source":"# Import Tensorflow into Colab\nimport tensorflow as tf\nimport tensorflow_hub as hub\nprint(\"TF Version\", tf.__version__)\nprint(\"TF Hub version\", hub.__version__)\n\n# Check for GPU availability\nprint(\"GPU\", \"available(YESS!!!)\" if tf.config.list_physical_devices(\"GPU\") else \"not available\")","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:16:41.52951Z","iopub.execute_input":"2021-11-18T05:16:41.529839Z","iopub.status.idle":"2021-11-18T05:16:46.92971Z","shell.execute_reply.started":"2021-11-18T05:16:41.529801Z","shell.execute_reply":"2021-11-18T05:16:46.92898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Getting our Data ready Turning into Tensors\n\nWith all machine learning models, our data has to be in numerical format so that's what we'll doing first. Turning our images into Tensors (numerical representations).\n\nLet's start by accessing our data and checking out the labels.\n","metadata":{}},{"cell_type":"code","source":"# Checkout the labels of our data\nimport pandas as pd\n\nlabels_csv = pd.read_csv(\"../input/dog-breed-identification/labels.csv\")\nprint(labels_csv.describe())","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:16:46.931139Z","iopub.execute_input":"2021-11-18T05:16:46.931407Z","iopub.status.idle":"2021-11-18T05:16:46.972443Z","shell.execute_reply.started":"2021-11-18T05:16:46.931372Z","shell.execute_reply":"2021-11-18T05:16:46.971528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels_csv.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:16:46.974085Z","iopub.execute_input":"2021-11-18T05:16:46.974371Z","iopub.status.idle":"2021-11-18T05:16:46.982883Z","shell.execute_reply.started":"2021-11-18T05:16:46.974333Z","shell.execute_reply":"2021-11-18T05:16:46.981861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# How many images are there of each breed?\n\nlabels_csv[\"breed\"].value_counts().plot.bar(figsize= (20,30))","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:16:46.984812Z","iopub.execute_input":"2021-11-18T05:16:46.985115Z","iopub.status.idle":"2021-11-18T05:16:49.519765Z","shell.execute_reply.started":"2021-11-18T05:16:46.985079Z","shell.execute_reply":"2021-11-18T05:16:49.519123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the mean of the the count values\n\nlabels_csv[\"breed\"].value_counts().mean()","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:16:49.520832Z","iopub.execute_input":"2021-11-18T05:16:49.521357Z","iopub.status.idle":"2021-11-18T05:16:49.530871Z","shell.execute_reply.started":"2021-11-18T05:16:49.52132Z","shell.execute_reply":"2021-11-18T05:16:49.530012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the median of the count for more accurate value or avoid error\nlabels_csv[\"breed\"].value_counts().median()","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:16:49.532717Z","iopub.execute_input":"2021-11-18T05:16:49.533104Z","iopub.status.idle":"2021-11-18T05:16:49.541276Z","shell.execute_reply.started":"2021-11-18T05:16:49.533068Z","shell.execute_reply":"2021-11-18T05:16:49.540311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's view an image\nfrom IPython.display import Image\nImage(\"../input/dog-breed-identification/train/001513dfcb2ffafc82cccf4d8bbaba97.jpg\")","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:16:49.545735Z","iopub.execute_input":"2021-11-18T05:16:49.545942Z","iopub.status.idle":"2021-11-18T05:16:49.560607Z","shell.execute_reply.started":"2021-11-18T05:16:49.545919Z","shell.execute_reply":"2021-11-18T05:16:49.559871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Getting images and their labels\n\nlet's get a list of all of our image file pathnames.","metadata":{"execution":{"iopub.status.busy":"2021-11-05T13:59:15.12401Z","iopub.execute_input":"2021-11-05T13:59:15.124696Z","iopub.status.idle":"2021-11-05T13:59:15.128917Z","shell.execute_reply.started":"2021-11-05T13:59:15.12466Z","shell.execute_reply":"2021-11-05T13:59:15.128031Z"}}},{"cell_type":"code","source":"labels_csv.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:16:49.562124Z","iopub.execute_input":"2021-11-18T05:16:49.562513Z","iopub.status.idle":"2021-11-18T05:16:49.572405Z","shell.execute_reply.started":"2021-11-18T05:16:49.562478Z","shell.execute_reply":"2021-11-18T05:16:49.571744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create pathnames from image ID's\n\nfilenames = [\"../input/dog-breed-identification/train/\"+fname+\".jpg\" for fname in labels_csv[\"id\"]]\nfilenames","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:16:49.573467Z","iopub.execute_input":"2021-11-18T05:16:49.574097Z","iopub.status.idle":"2021-11-18T05:16:49.600345Z","shell.execute_reply.started":"2021-11-18T05:16:49.574061Z","shell.execute_reply":"2021-11-18T05:16:49.599534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check wheather number of filenames matches number of actual image files\n\nimport os\nif len(os.listdir(\"../input/dog-breed-identification/train/\")) == len(filenames):\n    print(\"Filenames match actual amount of files !! proceed\")\nelse:\n    print(\"Filename do not match actual amount of files check the target directoru\")\n","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:16:49.601668Z","iopub.execute_input":"2021-11-18T05:16:49.601987Z","iopub.status.idle":"2021-11-18T05:16:49.614166Z","shell.execute_reply.started":"2021-11-18T05:16:49.601931Z","shell.execute_reply":"2021-11-18T05:16:49.613355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# One more check\nImage(filenames[9000])","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:16:49.615634Z","iopub.execute_input":"2021-11-18T05:16:49.61589Z","iopub.status.idle":"2021-11-18T05:16:49.628196Z","shell.execute_reply.started":"2021-11-18T05:16:49.615856Z","shell.execute_reply":"2021-11-18T05:16:49.62744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels_csv[\"breed\"][9000]","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:16:49.62952Z","iopub.execute_input":"2021-11-18T05:16:49.629761Z","iopub.status.idle":"2021-11-18T05:16:49.636252Z","shell.execute_reply.started":"2021-11-18T05:16:49.62973Z","shell.execute_reply":"2021-11-18T05:16:49.635372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since we've now got our training image filepaths in a list,\nlet's prepare our labels.\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nlabels = labels_csv[\"breed\"].to_numpy()\n# labels = np.array(labels) # does same thing as above\nlabels","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:16:49.637658Z","iopub.execute_input":"2021-11-18T05:16:49.63854Z","iopub.status.idle":"2021-11-18T05:16:49.645194Z","shell.execute_reply.started":"2021-11-18T05:16:49.638505Z","shell.execute_reply":"2021-11-18T05:16:49.644421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(labels)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:16:49.646766Z","iopub.execute_input":"2021-11-18T05:16:49.647376Z","iopub.status.idle":"2021-11-18T05:16:49.653726Z","shell.execute_reply.started":"2021-11-18T05:16:49.647339Z","shell.execute_reply":"2021-11-18T05:16:49.652669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# See if number of labels matches with number of fileames\nif len(labels) == len(filenames):\n    print(\"Number of labels matches number of filenames\")\nelse:\n    print(\"Number of labels does not match number of fileames, check data directories\")","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:16:49.655103Z","iopub.execute_input":"2021-11-18T05:16:49.655774Z","iopub.status.idle":"2021-11-18T05:16:49.661279Z","shell.execute_reply.started":"2021-11-18T05:16:49.655741Z","shell.execute_reply":"2021-11-18T05:16:49.660478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Find the unique label values\nunique_breeds = np.unique(labels)\nlen(unique_breeds)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:16:49.662616Z","iopub.execute_input":"2021-11-18T05:16:49.663051Z","iopub.status.idle":"2021-11-18T05:16:49.680105Z","shell.execute_reply.started":"2021-11-18T05:16:49.663016Z","shell.execute_reply":"2021-11-18T05:16:49.679353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Turn a single label into an array of booleans\nprint(labels[0])\nlabels[0] == unique_breeds","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:16:49.681152Z","iopub.execute_input":"2021-11-18T05:16:49.681732Z","iopub.status.idle":"2021-11-18T05:16:49.68962Z","shell.execute_reply.started":"2021-11-18T05:16:49.681697Z","shell.execute_reply":"2021-11-18T05:16:49.688662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Turn every labels into boolean array\nboolean_labels = [label == unique_breeds for label in labels]\nboolean_labels[:2]","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:16:49.690943Z","iopub.execute_input":"2021-11-18T05:16:49.691359Z","iopub.status.idle":"2021-11-18T05:16:49.782715Z","shell.execute_reply.started":"2021-11-18T05:16:49.691321Z","shell.execute_reply":"2021-11-18T05:16:49.78198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(boolean_labels)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:16:49.783662Z","iopub.execute_input":"2021-11-18T05:16:49.78392Z","iopub.status.idle":"2021-11-18T05:16:49.790367Z","shell.execute_reply.started":"2021-11-18T05:16:49.783877Z","shell.execute_reply":"2021-11-18T05:16:49.788582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Example : Turning boolean aarray into integers\nprint(labels[0]) # original label\nprint(np.where(unique_breeds == labels[0])) # Index where label occurs\nprint(boolean_labels[0].argmax()) # index where label occurs in boolean array\nprint(boolean_labels[0].astype(int)) # There will be a 1 where the sample labels occurs","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:16:49.791557Z","iopub.execute_input":"2021-11-18T05:16:49.79232Z","iopub.status.idle":"2021-11-18T05:16:49.800201Z","shell.execute_reply.started":"2021-11-18T05:16:49.792185Z","shell.execute_reply":"2021-11-18T05:16:49.799367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Creating our own validation set\n\nSince the dataset from kaggle doesn't come with validation set that's why we're creating a new validation set from the data.","metadata":{}},{"cell_type":"code","source":"# Setup X and y variable\n\nX = filenames\ny = boolean_labels\n","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:16:49.801335Z","iopub.execute_input":"2021-11-18T05:16:49.802249Z","iopub.status.idle":"2021-11-18T05:16:49.805885Z","shell.execute_reply.started":"2021-11-18T05:16:49.802214Z","shell.execute_reply":"2021-11-18T05:16:49.805091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(filenames)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:16:49.807215Z","iopub.execute_input":"2021-11-18T05:16:49.808065Z","iopub.status.idle":"2021-11-18T05:16:49.816037Z","shell.execute_reply.started":"2021-11-18T05:16:49.808005Z","shell.execute_reply":"2021-11-18T05:16:49.815285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We're going to start off experimeting with ~1000 images and increase as needed","metadata":{}},{"cell_type":"code","source":"# Set number of images to use for experimeting\nNUM_IMAGES = 1000 #@param {type:\"slider\", min:1000, max:10000,step:1000}\nNUM_IMAGES","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:16:49.817389Z","iopub.execute_input":"2021-11-18T05:16:49.817763Z","iopub.status.idle":"2021-11-18T05:16:49.825353Z","shell.execute_reply.started":"2021-11-18T05:16:49.817728Z","shell.execute_reply":"2021-11-18T05:16:49.824442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's split our data into train and validation sets\n\nfrom sklearn.model_selection import train_test_split\n\n# Split them into training and validation of total size NUM_IMAGES\nX_train, X_val, y_train, y_val = train_test_split(X[:NUM_IMAGES],\n                                                 y[:NUM_IMAGES],\n                                                 test_size = 0.2,\n                                                 random_state = 42)\n\nlen(X_train), len(y_train), len(X_val), len(y_val)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:16:49.82698Z","iopub.execute_input":"2021-11-18T05:16:49.827527Z","iopub.status.idle":"2021-11-18T05:16:50.380956Z","shell.execute_reply.started":"2021-11-18T05:16:49.827492Z","shell.execute_reply":"2021-11-18T05:16:50.380218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's have a geer at the training data\nX_train[:5], y_train[:2]\n","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:16:50.386338Z","iopub.execute_input":"2021-11-18T05:16:50.386541Z","iopub.status.idle":"2021-11-18T05:16:50.392751Z","shell.execute_reply.started":"2021-11-18T05:16:50.386517Z","shell.execute_reply":"2021-11-18T05:16:50.392007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing images (Turning images into Tensors)\n\nTo preprocess our images into Tensors we're going to write a function which does a few things:\n\n* Take an image filepath as input\n* Use Tensorflow to read the file and save it to a variable `image`\n\n* Turn `image` (a jpg) into Tensors\n* Normalize our image (Convert color channel values from 0-255 to 0-1)\n* Resize the `image` to be a shape of (224, 224)\n* Return the modified `image`\n\nBefore we do, let's see what importing an image looks like.","metadata":{}},{"cell_type":"code","source":"# Convert image to a Numpy array\nfrom matplotlib.pyplot import imread\nimage = imread(filenames[42])\nimage.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:16:50.394179Z","iopub.execute_input":"2021-11-18T05:16:50.394733Z","iopub.status.idle":"2021-11-18T05:16:50.409693Z","shell.execute_reply.started":"2021-11-18T05:16:50.394697Z","shell.execute_reply":"2021-11-18T05:16:50.408999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:16:50.410886Z","iopub.execute_input":"2021-11-18T05:16:50.411343Z","iopub.status.idle":"2021-11-18T05:16:50.417455Z","shell.execute_reply.started":"2021-11-18T05:16:50.411307Z","shell.execute_reply":"2021-11-18T05:16:50.41663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image.max()","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:16:50.418897Z","iopub.execute_input":"2021-11-18T05:16:50.4194Z","iopub.status.idle":"2021-11-18T05:16:50.428002Z","shell.execute_reply.started":"2021-11-18T05:16:50.419351Z","shell.execute_reply":"2021-11-18T05:16:50.427237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image[:2]","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:16:50.42899Z","iopub.execute_input":"2021-11-18T05:16:50.42917Z","iopub.status.idle":"2021-11-18T05:16:50.436929Z","shell.execute_reply.started":"2021-11-18T05:16:50.429149Z","shell.execute_reply":"2021-11-18T05:16:50.436118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Turn image into Tensors\ntf.constant(image)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:16:50.437963Z","iopub.execute_input":"2021-11-18T05:16:50.439427Z","iopub.status.idle":"2021-11-18T05:16:52.623401Z","shell.execute_reply.started":"2021-11-18T05:16:50.439392Z","shell.execute_reply":"2021-11-18T05:16:52.622286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we've seen what an image looks like as a Tensor, let's make a function to preprocess them.","metadata":{}},{"cell_type":"code","source":"# Define image size\nIMG_SIZE = 224\n\n# Create a function for preprocessing images\ndef process_image(image_path, img_size = IMG_SIZE):\n    \"\"\"\n    Takes an image file path and turns the image into a Tensor\n    \"\"\"\n    # Read in an image file\n    image = tf.io.read_file(image_path)\n    # Turn the jpeg image into numerical Tensor with 3 color channels (Read, Green, blue)\n    image = tf.image.decode_jpeg(image, channels = 3)\n    # Convert the colour channel values from 0-255 to 0-1 values\n    image = tf.image.convert_image_dtype(image, tf.float32)\n    # Resize the image to our desired value (224, 224)\n    image = tf.image.resize(image, size = [IMG_SIZE, IMG_SIZE])\n    \n    return image\n    ","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:16:52.625186Z","iopub.execute_input":"2021-11-18T05:16:52.625494Z","iopub.status.idle":"2021-11-18T05:16:52.633428Z","shell.execute_reply.started":"2021-11-18T05:16:52.625458Z","shell.execute_reply":"2021-11-18T05:16:52.63262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tensor = tf.io.read_file(filenames[26])\n# tensor","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:16:52.635083Z","iopub.execute_input":"2021-11-18T05:16:52.635397Z","iopub.status.idle":"2021-11-18T05:16:52.65129Z","shell.execute_reply.started":"2021-11-18T05:16:52.635363Z","shell.execute_reply":"2021-11-18T05:16:52.650459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tf.image.decode_jpeg(tensor, channels = 3)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:16:52.652626Z","iopub.execute_input":"2021-11-18T05:16:52.653422Z","iopub.status.idle":"2021-11-18T05:16:52.656755Z","shell.execute_reply.started":"2021-11-18T05:16:52.653386Z","shell.execute_reply":"2021-11-18T05:16:52.655976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Turning our Data into batches\n\nwhy to turn our data into batches?\n\nLet's say you're trying to process 10,000+ images in one go.. They all might not fit into memory.\n\nso that's why we do about`32 images (this the batch size)` at a time ( you can manually adjust the batch size if need be).\n\nIn order to  Tensorflow effectively , we need our data in the form of Tensor Tuples which look like this:\n\n`(image, label)`","metadata":{}},{"cell_type":"code","source":"# Create a simple function to retur a tuple (image, label)\ndef get_image_label(image_path, label):\n    \"\"\"\n    Takes an image file path name and the associated label,\n    process the image and returns a tuple of (image. label).\n    \"\"\"\n    \n    image = process_image(image_path)\n    return image, label","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:16:52.658442Z","iopub.execute_input":"2021-11-18T05:16:52.658965Z","iopub.status.idle":"2021-11-18T05:16:52.666055Z","shell.execute_reply.started":"2021-11-18T05:16:52.658927Z","shell.execute_reply":"2021-11-18T05:16:52.665125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Demo of the above\n(process_image(X[42], tf.constant(y[42])))\n\n","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:16:52.667734Z","iopub.execute_input":"2021-11-18T05:16:52.668008Z","iopub.status.idle":"2021-11-18T05:16:52.70747Z","shell.execute_reply.started":"2021-11-18T05:16:52.667973Z","shell.execute_reply":"2021-11-18T05:16:52.706684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we've got a way to turn our data into tuples of Tensors\nin the form of : `(image, label)` , let make a function to turn all of our data (`X` and `y`) into batches","metadata":{}},{"cell_type":"code","source":"# Define the batch size, 32 is a good start\nBATCH_SIZE = 32\n\n# Create a function to turn data into batches\ndef create_data_batches(X, y = None, batch_size = BATCH_SIZE, valid_data = False, test_data = False):\n    \"\"\"\n    create batches of data our of image(X) and label (y) pairs\n    it shuffles the data if it's training data but doesn't shuffle if its's validation data.\n    also accepts test data as input (no labels)\n    \"\"\"\n    # If the data is test dataset, we probably don't have labels\n    if test_data:\n        print(\"Creating test data batches...\")\n        data = tf.data.Dataset.from_tensor_slices((tf.constant(X))) # only filepaths (no labels)\n        data_batch = data.map(process_image).batch(BATCH_SIZE)\n        return data_batch\n    \n    # If the data is valid datasets, we don't need to shuffle it\n    elif valid_data:\n        print(\"Creating validation data batches...\")\n        data = tf.data.Dataset.from_tensor_slices((tf.constant(X), # file path\n                                                 tf.constant(y))) # labels\n        data_batch = data.map(get_image_label).batch(BATCH_SIZE)\n        return data_batch\n        \n    else:\n        print(\"Creating training data batches....\")\n        # Turn filepaths and labels into Tensors\n        data = tf.data.Dataset.from_tensor_slices((tf.constant(X),\n                                                 tf.constant(y)))\n        \n        # Shuffling pathnames and labels before mapping image processor function is faster than shuffling\n        data = data.shuffle(buffer_size = len(X))\n        \n        # Create (image, label) tuples (this also turn the image path into a preprocessed iamge)\n        data = data.map(get_image_label)\n        \n        # Turn the training data into batches\n        data_batch = data.batch(BATCH_SIZE)\n        return data_batch","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:16:52.708916Z","iopub.execute_input":"2021-11-18T05:16:52.709715Z","iopub.status.idle":"2021-11-18T05:16:52.71986Z","shell.execute_reply.started":"2021-11-18T05:16:52.709676Z","shell.execute_reply":"2021-11-18T05:16:52.718924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating training and validation data batches\ntrain_data = create_data_batches(X_train, y_train)\nval_data = create_data_batches(X_val,y_val, valid_data = True)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:16:52.72121Z","iopub.execute_input":"2021-11-18T05:16:52.722131Z","iopub.status.idle":"2021-11-18T05:16:52.886255Z","shell.execute_reply.started":"2021-11-18T05:16:52.722079Z","shell.execute_reply":"2021-11-18T05:16:52.885503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check out the different attributes of our data batches\ntrain_data.element_spec, val_data.element_spec","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:16:52.887422Z","iopub.execute_input":"2021-11-18T05:16:52.887676Z","iopub.status.idle":"2021-11-18T05:16:52.895317Z","shell.execute_reply.started":"2021-11-18T05:16:52.887642Z","shell.execute_reply":"2021-11-18T05:16:52.894486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y[0]","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:16:52.896489Z","iopub.execute_input":"2021-11-18T05:16:52.897254Z","iopub.status.idle":"2021-11-18T05:16:52.907233Z","shell.execute_reply.started":"2021-11-18T05:16:52.897216Z","shell.execute_reply":"2021-11-18T05:16:52.906351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualizing Data Batches\n\nOur data is now in batches, however these can be a little hard to understand/comprehend , let's visualize the batches","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Create a function for viewing images in a data batch\n\ndef show_25_images(images, labels):\n    \"\"\"\n    Display a plot of 25 images and their labels from a data batch\n    \"\"\"\n    # Setup the figure\n    plt.figure(figsize = (10,10))\n    \n    # Loop through 25 (for displaying 25 images)\n    for i in range(25):\n        ax = plt.subplot(5, 5, i+1)\n        # Display an image\n        plt.imshow(images[i])\n        # Add the image label as the title\n        plt.title(unique_breeds[labels[i].argmax()])\n        # Turn the grid lines off\n        plt.axis(\"off\")\n        ","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:16:52.908982Z","iopub.execute_input":"2021-11-18T05:16:52.909184Z","iopub.status.idle":"2021-11-18T05:16:52.918045Z","shell.execute_reply.started":"2021-11-18T05:16:52.90916Z","shell.execute_reply":"2021-11-18T05:16:52.917347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images, train_labels = next(train_data.as_numpy_iterator())\nlen(train_images), len(train_labels)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:16:52.921436Z","iopub.execute_input":"2021-11-18T05:16:52.923024Z","iopub.status.idle":"2021-11-18T05:16:53.182233Z","shell.execute_reply.started":"2021-11-18T05:16:52.922994Z","shell.execute_reply":"2021-11-18T05:16:53.181393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now let's visualize the data in a training batch\nshow_25_images(train_images, train_labels)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:16:53.183437Z","iopub.execute_input":"2021-11-18T05:16:53.184404Z","iopub.status.idle":"2021-11-18T05:16:54.8155Z","shell.execute_reply.started":"2021-11-18T05:16:53.184366Z","shell.execute_reply":"2021-11-18T05:16:54.814767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize the validation set\nval_images, val_labels =  next(val_data.as_numpy_iterator())\nshow_25_images(val_images, val_labels)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:16:54.816753Z","iopub.execute_input":"2021-11-18T05:16:54.817094Z","iopub.status.idle":"2021-11-18T05:16:56.609499Z","shell.execute_reply.started":"2021-11-18T05:16:54.817054Z","shell.execute_reply":"2021-11-18T05:16:56.608841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Building the models\n\nBefore we build a model, there are a few things we need to define:\n\n* The input shape (our images shape, in the form of Tensors) to our model.\n* The output shape(image labels, in the form of Tensors) of our Model.\n* The URL of the model we want to use. from tensorflow hub\n\nhttps://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5\n","metadata":{}},{"cell_type":"code","source":"# Setup input shape to the model\n\nINPUT_SHAPE = [None, IMG_SIZE, IMG_SIZE, 3]\n\n\n# Setup output shape of our model\nOUTPUT_SHAPE = len(unique_breeds)\n\n# Setup Model URL from TensorFlow Hub\nMODEL_URL = \"https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5\"","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:16:56.61066Z","iopub.execute_input":"2021-11-18T05:16:56.610992Z","iopub.status.idle":"2021-11-18T05:16:56.615164Z","shell.execute_reply.started":"2021-11-18T05:16:56.610961Z","shell.execute_reply":"2021-11-18T05:16:56.614543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we've got our inputs, outputs and model ready to go.\nLet's put them together into a Keras deep learing model\n\n\nKnowing this, let's create a function which:\n* Takes the input shape, output shape and the model we've chosen as parameters.\n* Define the layers in a Keras model in sequential fashion (Do this first then this m then that).\n* Complies the model (says it should be evaluated and improved).\n* Build the model (tells the model the input shape it'll be getting)\n* Finally return the model.\n","metadata":{}},{"cell_type":"code","source":"# Create a function which builds a Keras model\n\ndef create_model(input_shape = INPUT_SHAPE, output_shape = OUTPUT_SHAPE, model_url = MODEL_URL):\n    print(\"Building model with: \", MODEL_URL)\n    \n    # Setup the model layers\n    model = tf.keras.Sequential([hub.KerasLayer(MODEL_URL), # Layer 1 (input layer)\n                                tf.keras.layers.Dense(units = OUTPUT_SHAPE,  \n                                activation =\"softmax\")]) # Layer 2 (output Layer)\n    \n    # Compile the model\n    model.compile(loss = tf.keras.losses.CategoricalCrossentropy(),\n                optimizer = tf.keras.optimizers.Adam(),\n                metrics = [\"accuracy\"])\n    \n    # Build the model\n    model.build(INPUT_SHAPE)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:16:56.616623Z","iopub.execute_input":"2021-11-18T05:16:56.617022Z","iopub.status.idle":"2021-11-18T05:16:56.625491Z","shell.execute_reply.started":"2021-11-18T05:16:56.61698Z","shell.execute_reply":"2021-11-18T05:16:56.624677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = create_model()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:16:56.626769Z","iopub.execute_input":"2021-11-18T05:16:56.627119Z","iopub.status.idle":"2021-11-18T05:17:00.699754Z","shell.execute_reply.started":"2021-11-18T05:16:56.627079Z","shell.execute_reply":"2021-11-18T05:17:00.698668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating callbacks\n\ncallbacks are helper function a model can use training to do such things as save its progress, check its progress or stop training early if a model stops improving.\n\n\nwe'll create two callbacks, one for TensorBoard which helps track our models progress and another for early stopping which prevents our model from training for too long.\n\n### TensorBoard CallBack\n\nTo setup a TensorBoard callback, we eed to do 3 things:\n1. Load The TensorBoard Notebook extension\n2. Create a TensorBoard callback which is able to save logs to a directory and pass it to our models `fit()` functions\n3. Visualize our models training logs with the `%tensorboard` magic function (we'll do this after model training).","metadata":{}},{"cell_type":"code","source":"# Load TensorBoard Notebook extension\n%load_ext tensorboard\n\n","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:17:00.70103Z","iopub.execute_input":"2021-11-18T05:17:00.701285Z","iopub.status.idle":"2021-11-18T05:17:00.71432Z","shell.execute_reply.started":"2021-11-18T05:17:00.701251Z","shell.execute_reply":"2021-11-18T05:17:00.713511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! mkdir logs\n! ls\n","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:17:00.716029Z","iopub.execute_input":"2021-11-18T05:17:00.71629Z","iopub.status.idle":"2021-11-18T05:17:02.121136Z","shell.execute_reply.started":"2021-11-18T05:17:00.716256Z","shell.execute_reply":"2021-11-18T05:17:02.120345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import datetime\n\n# Create a function to buiild a TensorBoard callback\ndef create_tensorboard_callback():\n    # Create a log directory for storing TensorBoard logs\n    logdir = os.path.join('logs',\n                         # Make it so the logs get tracked whenever we run an experiment \n                         datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n    \n    return tf.keras.callbacks.TensorBoard(logdir)\n    ","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:17:02.124271Z","iopub.execute_input":"2021-11-18T05:17:02.124511Z","iopub.status.idle":"2021-11-18T05:17:02.130355Z","shell.execute_reply.started":"2021-11-18T05:17:02.124483Z","shell.execute_reply":"2021-11-18T05:17:02.129065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Early Stopping Callback\n\nearly stopping helps stop our model from overfitting by stopping training if a certain evaluation metric stop\n","metadata":{"execution":{"iopub.status.busy":"2021-11-15T07:25:32.103166Z","iopub.execute_input":"2021-11-15T07:25:32.103698Z","iopub.status.idle":"2021-11-15T07:25:32.114617Z","shell.execute_reply.started":"2021-11-15T07:25:32.10366Z","shell.execute_reply":"2021-11-15T07:25:32.110994Z"}}},{"cell_type":"code","source":"# Create early stopping callback\n\nearly_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",\n                                                 patience = 3)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:17:02.132061Z","iopub.execute_input":"2021-11-18T05:17:02.132488Z","iopub.status.idle":"2021-11-18T05:17:02.139367Z","shell.execute_reply.started":"2021-11-18T05:17:02.132428Z","shell.execute_reply":"2021-11-18T05:17:02.138607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training a model (on subset of data)\n\nour first model is only going to train on 1000 images, to make sure everything is working","metadata":{}},{"cell_type":"code","source":"NUM_EPOCHS = 100  #@param {type:\"slider\", min:10, max:100, step:10}","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:17:02.140755Z","iopub.execute_input":"2021-11-18T05:17:02.14113Z","iopub.status.idle":"2021-11-18T05:17:02.148047Z","shell.execute_reply.started":"2021-11-18T05:17:02.141078Z","shell.execute_reply":"2021-11-18T05:17:02.147305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check to make sure we're still running on a GPU\nprint(\"GPU\", \"avilable (yess)\" if tf.config.list_physical_devices(\"GPU\") else \"not avilable\")","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:17:02.149574Z","iopub.execute_input":"2021-11-18T05:17:02.149828Z","iopub.status.idle":"2021-11-18T05:17:02.15868Z","shell.execute_reply.started":"2021-11-18T05:17:02.149795Z","shell.execute_reply":"2021-11-18T05:17:02.157963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's create a function which trains a model.\n\n* Create a model using `create_model()`\n* Setup a TensorBoard callback using `create_tensorboard_callback()`\n* Call the `fit()` function on our model passing it the training data, validation data, number of epochs to train for (`NUM_EPOCHES`) and the callbacks we'd like to use\n* Return the model","metadata":{"execution":{"iopub.status.busy":"2021-11-15T07:37:02.674038Z","iopub.execute_input":"2021-11-15T07:37:02.674576Z","iopub.status.idle":"2021-11-15T07:37:02.680138Z","shell.execute_reply.started":"2021-11-15T07:37:02.674538Z","shell.execute_reply":"2021-11-15T07:37:02.679144Z"}}},{"cell_type":"code","source":"# Build a function to train and return a trained model\n\ndef train_model():\n    \"\"\"\n    Train a given model and returns the trained version.\n    \"\"\"\n    # Create a model\n    model = create_model()\n    \n    # Create new TesorBoard session everytime we train a model\n    tensorboard = create_tensorboard_callback()\n    \n    # Fit the model to the data passing it the callbacks we created\n    model.fit(x = train_data, epochs = NUM_EPOCHS, validation_data = val_data,\n             validation_freq = 1,\n             callbacks = [tensorboard, early_stopping])\n    # return the fitted model\n    return model\n    ","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:17:02.159775Z","iopub.execute_input":"2021-11-18T05:17:02.160164Z","iopub.status.idle":"2021-11-18T05:17:02.16697Z","shell.execute_reply.started":"2021-11-18T05:17:02.160128Z","shell.execute_reply":"2021-11-18T05:17:02.16627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fit eh model to the data\nmodel = train_model()\n","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:17:02.16809Z","iopub.execute_input":"2021-11-18T05:17:02.168576Z","iopub.status.idle":"2021-11-18T05:17:52.142339Z","shell.execute_reply.started":"2021-11-18T05:17:02.168531Z","shell.execute_reply":"2021-11-18T05:17:52.141478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! ls\n","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:17:52.143863Z","iopub.execute_input":"2021-11-18T05:17:52.144207Z","iopub.status.idle":"2021-11-18T05:17:52.864569Z","shell.execute_reply.started":"2021-11-18T05:17:52.144168Z","shell.execute_reply":"2021-11-18T05:17:52.863727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! cd logs","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:17:52.868177Z","iopub.execute_input":"2021-11-18T05:17:52.868441Z","iopub.status.idle":"2021-11-18T05:17:53.591468Z","shell.execute_reply.started":"2021-11-18T05:17:52.868411Z","shell.execute_reply":"2021-11-18T05:17:53.589465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! ls","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:17:53.593494Z","iopub.execute_input":"2021-11-18T05:17:53.593814Z","iopub.status.idle":"2021-11-18T05:17:54.308612Z","shell.execute_reply.started":"2021-11-18T05:17:53.593772Z","shell.execute_reply":"2021-11-18T05:17:54.307793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Checking the TensorBoard Logs\nThe TensorBoard magic function (`%tensorboard`) will access the logs directory we created earlier and visualize its contents","metadata":{"execution":{"iopub.status.busy":"2021-11-15T07:53:39.411938Z","iopub.execute_input":"2021-11-15T07:53:39.412733Z","iopub.status.idle":"2021-11-15T07:53:39.418156Z","shell.execute_reply.started":"2021-11-15T07:53:39.412695Z","shell.execute_reply":"2021-11-15T07:53:39.41701Z"}}},{"cell_type":"code","source":"! kill 6484\n%tensorboard --logdir logs\n","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:17:54.310269Z","iopub.execute_input":"2021-11-18T05:17:54.310581Z","iopub.status.idle":"2021-11-18T05:17:59.094691Z","shell.execute_reply.started":"2021-11-18T05:17:54.310532Z","shell.execute_reply":"2021-11-18T05:17:59.093855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Making and evaluating prediction using trained model","metadata":{}},{"cell_type":"code","source":"val_data","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:17:59.096669Z","iopub.execute_input":"2021-11-18T05:17:59.09696Z","iopub.status.idle":"2021-11-18T05:17:59.50848Z","shell.execute_reply.started":"2021-11-18T05:17:59.096923Z","shell.execute_reply":"2021-11-18T05:17:59.507805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make prediction on the validation data (not used to train on)\nprediction = model.predict(val_data, verbose = 1)\nprediction","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:17:59.51028Z","iopub.execute_input":"2021-11-18T05:17:59.510643Z","iopub.status.idle":"2021-11-18T05:18:00.597028Z","shell.execute_reply.started":"2021-11-18T05:17:59.510606Z","shell.execute_reply":"2021-11-18T05:18:00.596144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:18:00.598616Z","iopub.execute_input":"2021-11-18T05:18:00.598898Z","iopub.status.idle":"2021-11-18T05:18:00.605808Z","shell.execute_reply.started":"2021-11-18T05:18:00.598861Z","shell.execute_reply":"2021-11-18T05:18:00.604685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(y_val)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:18:00.60762Z","iopub.execute_input":"2021-11-18T05:18:00.607961Z","iopub.status.idle":"2021-11-18T05:18:00.618478Z","shell.execute_reply.started":"2021-11-18T05:18:00.607924Z","shell.execute_reply":"2021-11-18T05:18:00.617367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(unique_breeds)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:18:00.620018Z","iopub.execute_input":"2021-11-18T05:18:00.620492Z","iopub.status.idle":"2021-11-18T05:18:00.629079Z","shell.execute_reply.started":"2021-11-18T05:18:00.620451Z","shell.execute_reply":"2021-11-18T05:18:00.628214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# First Prediction\nindex = 69\nprint(prediction[0])\nprint(f\"Max value (probability of prediction):{np.max(prediction[index])}\")\nprint(f\"Sum:{np.sum(prediction[index])}\")\nprint(f\"Max index: {np.argmax(prediction[index])}\")\nprint(f\"Predicted label: {unique_breeds[np.argmax(prediction[index])]}\")","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:18:00.630935Z","iopub.execute_input":"2021-11-18T05:18:00.631495Z","iopub.status.idle":"2021-11-18T05:18:00.641256Z","shell.execute_reply.started":"2021-11-18T05:18:00.631454Z","shell.execute_reply":"2021-11-18T05:18:00.640125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Having the above functionality is great but we want to be able to do it at scale.\n\nand it would have even better if we could see the image the prediction is being made on !\n\n**Note:** Predicition probabilities are also known as `confidence level`","metadata":{"execution":{"iopub.status.busy":"2021-11-16T06:33:33.824829Z","iopub.execute_input":"2021-11-16T06:33:33.825172Z","iopub.status.idle":"2021-11-16T06:33:33.836634Z","shell.execute_reply.started":"2021-11-16T06:33:33.82514Z","shell.execute_reply":"2021-11-16T06:33:33.834282Z"}}},{"cell_type":"code","source":"# Turn probabilities into their respective label (Easier to understand)\n\ndef get_pred_label(prediction_probabilities):\n    \"\"\"\n    Turn an array of prediction probabilities into a label\n    \"\"\"\n    \n    return unique_breeds[np.argmax(prediction_probabilities)]\n\n# Get a predicted label based on an array of prediction probabilities\n\npred_label = get_pred_label(prediction[69])\npred_label","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:18:00.643113Z","iopub.execute_input":"2021-11-18T05:18:00.643469Z","iopub.status.idle":"2021-11-18T05:18:00.651203Z","shell.execute_reply.started":"2021-11-18T05:18:00.64343Z","shell.execute_reply":"2021-11-18T05:18:00.650342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"since our validation data is still in a batch dataset,\nwe'll have to ubatchfy it to make predicitons on the validation images and them compare those predicitons to the validation labels(truth labels).","metadata":{}},{"cell_type":"code","source":"images_ = []\nlabels_ = []\n\n# loop through unbatched data\nfor image, label in val_data.unbatch().as_numpy_iterator():\n    images_.append(image)\n    labels_.append(label)\n    \nlabels_[0], images_[0]","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:18:00.65277Z","iopub.execute_input":"2021-11-18T05:18:00.653358Z","iopub.status.idle":"2021-11-18T05:18:01.197016Z","shell.execute_reply.started":"2021-11-18T05:18:00.653308Z","shell.execute_reply":"2021-11-18T05:18:01.196255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a function to unbatch a batch dataset\ndef unbatchify(data):\n    \"\"\"\n    Takes a batched dataset of (image, label) Tensors and return separate arrays\n    of images and labels.\n    \"\"\"\n    images = []\n    labels = []\n    # Loop through unbatched data\n    for image , label in data.unbatch().as_numpy_iterator():\n        images.append(image)\n        labels.append(unique_breeds[np.argmax(label)])\n    return images, labels\n\n\n# unbatchify the validation data\n\nval_images , val_labels = unbatchify(val_data)\nval_images[0], val_labels[0]\n","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:18:01.198565Z","iopub.execute_input":"2021-11-18T05:18:01.198852Z","iopub.status.idle":"2021-11-18T05:18:01.785008Z","shell.execute_reply.started":"2021-11-18T05:18:01.198821Z","shell.execute_reply":"2021-11-18T05:18:01.784256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_pred_label(val_labels[0])","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:18:01.786172Z","iopub.execute_input":"2021-11-18T05:18:01.78643Z","iopub.status.idle":"2021-11-18T05:18:01.791697Z","shell.execute_reply.started":"2021-11-18T05:18:01.786394Z","shell.execute_reply":"2021-11-18T05:18:01.790874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we've got ways to get :\n\n* Prediction labels\n* validation labels (truth labels)\n* validation images\n\nLet's make some function to make these all a bit more visualize\n\nwe'll create a function which:\n* Takes an array of predcition probabilities, an array of truth labels and an array of image and a integers.\n* Convert the prediction probabilities to a predicted label.\n* plot the predicted label, its predicted probability, the truth label and the target image on a single plot.","metadata":{}},{"cell_type":"code","source":"def plot_pred(prediction_probabilities, labels, images, n = 1):\n    \"\"\"\n    View the prediction , groud truth and imave for sample n\n    \"\"\"\n    pred_prob, true_label, image = prediction_probabilities[n], labels[n], images[n]\n    \n    # Get the pred label\n    pred_label = get_pred_label(pred_prob)\n    \n    # Plot image\n    plt.imshow(image)\n    plt.xticks([])\n    plt.yticks([])\n    \n    # Change the colour  of the title depending on if the prediction is right or wrong\n    if pred_label == true_label:\n        color = \"green\"\n    else:\n        color = \"red\"\n    \n    # Change plot title to be predicted , probability of prediction and truth label\n    plt.title(\"{} {:2.0f}% {}\".format(pred_label,np.max(pred_prob)*100, true_label), color = color)\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:18:01.793366Z","iopub.execute_input":"2021-11-18T05:18:01.793902Z","iopub.status.idle":"2021-11-18T05:18:01.802243Z","shell.execute_reply.started":"2021-11-18T05:18:01.793865Z","shell.execute_reply":"2021-11-18T05:18:01.801361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_pred(prediction_probabilities=prediction,\n         labels = val_labels,\n         images = val_images,\n         n = 77)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:18:01.80391Z","iopub.execute_input":"2021-11-18T05:18:01.804247Z","iopub.status.idle":"2021-11-18T05:18:01.90381Z","shell.execute_reply.started":"2021-11-18T05:18:01.80418Z","shell.execute_reply":"2021-11-18T05:18:01.902895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\nNow we've got one function to visualize our models top predictions, let's make another to view our models top 10 predictions. \n\nThis functions will:\n* Take an input of prediction probabilities array and a ground truth array and an integer.\n* Find the prediction using `get_pred_label()`\n* Find the top 10:\n    * Prediction probabilities indexes\n    * Prediction probabilities values\n    * Predicition labels\n* Plot the top 10 prediction probability values and labels, coloring the true label green","metadata":{}},{"cell_type":"code","source":"def plot_pred_conf(prediction_probabilities, labels, n=1):\n    \"\"\"\n    Plus the top 10 highest prediction confidences along with the true labels\n    for sample n.\n    \"\"\"\n    pred_prob, true_label = prediction_probabilities[n], labels[n]\n    \n    # Get the predicted label\n    pred_label = get_pred_label(pred_prob)\n    \n    # Find the top 10 prediction confidence indexes\n    top_10_pred_indexes = pred_prob.argsort()[-10:][::-1]\n    \n    # Find the top 10 prediction confidence values\n    top_10_pred_values = pred_prob[top_10_pred_indexes]\n    \n    # Find the top 10 prediction labels\n    top_10_pred_labels = unique_breeds[top_10_pred_indexes]\n    \n    # Setup plot \n    top_plot = plt.bar(np.arange(len(top_10_pred_labels)), top_10_pred_values,color =\"grey\")\n    \n    plt.xticks(np.arange(len(top_10_pred_labels)),\n              labels = top_10_pred_labels,\n              rotation = \"vertical\")\n    \n    # Change color of true  label\n    if np.isin(true_label, top_10_pred_labels):\n        top_plot[np.argmax(top_10_pred_labels == true_label)].set_color('green')\n    else:\n        pass\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:18:01.905184Z","iopub.execute_input":"2021-11-18T05:18:01.905428Z","iopub.status.idle":"2021-11-18T05:18:01.915506Z","shell.execute_reply.started":"2021-11-18T05:18:01.905399Z","shell.execute_reply":"2021-11-18T05:18:01.914724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_pred_conf(prediction_probabilities = prediction, labels = val_labels, n = 9)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:18:01.916801Z","iopub.execute_input":"2021-11-18T05:18:01.917095Z","iopub.status.idle":"2021-11-18T05:18:02.292027Z","shell.execute_reply.started":"2021-11-18T05:18:01.917057Z","shell.execute_reply":"2021-11-18T05:18:02.291356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we've got some function to help us visualize our predictions and evaluate our model let check our a few prediction","metadata":{}},{"cell_type":"code","source":"# Let's check out a few predictions and their differenct values\ni_multiplier = 10\nnum_rows = 3\nnum_cols = 2\nnum_images = num_rows* num_cols\n\nplt.figure(figsize =(10*num_cols, 5*num_rows))\nfor i in range(num_images):\n    plt.subplot(num_rows, 2* num_cols, 2* i+1)\n    plot_pred(prediction_probabilities = prediction,\n             labels = val_labels,\n             images = val_images,\n             n = i+i_multiplier)\n    plt.subplot(num_rows, 2*num_cols, 2 * i+2)\n    plot_pred_conf(prediction_probabilities = prediction,\n                  labels = val_labels,\n                  n = i +i_multiplier)\nplt.tight_layout(h_pad =1.0)    \nplt.show()\n    ","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:18:02.294792Z","iopub.execute_input":"2021-11-18T05:18:02.297696Z","iopub.status.idle":"2021-11-18T05:18:04.103636Z","shell.execute_reply.started":"2021-11-18T05:18:02.297656Z","shell.execute_reply":"2021-11-18T05:18:04.102992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" Create a confusion matrix with models predictions and true labels?\n \n ","metadata":{}},{"cell_type":"markdown","source":"## Save and Reload Models","metadata":{}},{"cell_type":"code","source":"# Create a function to save a model\ndef save_model(model , suffix = None):\n    \"\"\"\n    save a given model in a models directory and appedns a suffix(string)\n    \"\"\"\n    # Create a model directory pathname with current time\n    modeldir = os.path.join(\"models\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%s\"))\n    model_path = modeldir + '-'+ suffix + '.h5' # Save format of model\n    \n    print(f\"saving model to: {model_path}...\")\n    model.save(model_path)\n    return model_path\n","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:18:04.104665Z","iopub.execute_input":"2021-11-18T05:18:04.104996Z","iopub.status.idle":"2021-11-18T05:18:04.111524Z","shell.execute_reply.started":"2021-11-18T05:18:04.104966Z","shell.execute_reply":"2021-11-18T05:18:04.110643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a function to load a trained model\ndef load_model(model_path):\n    \"\"\"\n    Load a saved model from a specified path.\n    \"\"\"\n    print(f\"Loading saved model from: {model_path}\")\n    model = tf.keras.models.load_model(model_path,\n                                       custom_objects = {\"KerasLayer\": hub.KerasLayer})\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:18:04.113049Z","iopub.execute_input":"2021-11-18T05:18:04.113337Z","iopub.status.idle":"2021-11-18T05:18:04.123813Z","shell.execute_reply.started":"2021-11-18T05:18:04.11329Z","shell.execute_reply":"2021-11-18T05:18:04.122982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we've created the functions to save and load a trained models let's make sure they work\n","metadata":{}},{"cell_type":"code","source":"save_model(model, suffix = \"1000-images-mobilenetv2-Adam\")","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:18:04.125498Z","iopub.execute_input":"2021-11-18T05:18:04.12602Z","iopub.status.idle":"2021-11-18T05:18:04.34387Z","shell.execute_reply.started":"2021-11-18T05:18:04.125979Z","shell.execute_reply":"2021-11-18T05:18:04.343127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the trained model\nloaded_1000_image_model = load_model('models/20211118-05181637212684-1000-images-mobilenetv2-Adam.h5')","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:19:28.522444Z","iopub.execute_input":"2021-11-18T05:19:28.523069Z","iopub.status.idle":"2021-11-18T05:19:31.045834Z","shell.execute_reply.started":"2021-11-18T05:19:28.523033Z","shell.execute_reply":"2021-11-18T05:19:31.045057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the pre-saved model\nmodel.evaluate(val_data)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:19:33.716997Z","iopub.execute_input":"2021-11-18T05:19:33.717311Z","iopub.status.idle":"2021-11-18T05:19:34.375904Z","shell.execute_reply.started":"2021-11-18T05:19:33.717262Z","shell.execute_reply":"2021-11-18T05:19:34.375021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the loaded model\nloaded_1000_image_model.evaluate(val_data)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:19:34.377677Z","iopub.execute_input":"2021-11-18T05:19:34.378005Z","iopub.status.idle":"2021-11-18T05:19:35.486998Z","shell.execute_reply.started":"2021-11-18T05:19:34.377968Z","shell.execute_reply":"2021-11-18T05:19:35.486242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training a big dog model on the full data","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:18:04.621099Z","iopub.status.idle":"2021-11-18T05:18:04.621933Z","shell.execute_reply.started":"2021-11-18T05:18:04.621686Z","shell.execute_reply":"2021-11-18T05:18:04.621711Z"}}},{"cell_type":"code","source":"len(X), len(y)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:22:16.503719Z","iopub.execute_input":"2021-11-18T05:22:16.503986Z","iopub.status.idle":"2021-11-18T05:22:16.50926Z","shell.execute_reply.started":"2021-11-18T05:22:16.503956Z","shell.execute_reply":"2021-11-18T05:22:16.508345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(X_train)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:22:49.526875Z","iopub.execute_input":"2021-11-18T05:22:49.527278Z","iopub.status.idle":"2021-11-18T05:22:49.532548Z","shell.execute_reply.started":"2021-11-18T05:22:49.527232Z","shell.execute_reply":"2021-11-18T05:22:49.531202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create a data batch with the full dataset\nfull_data = create_data_batches(X, y)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:24:29.310834Z","iopub.execute_input":"2021-11-18T05:24:29.311115Z","iopub.status.idle":"2021-11-18T05:24:29.425573Z","shell.execute_reply.started":"2021-11-18T05:24:29.311082Z","shell.execute_reply":"2021-11-18T05:24:29.424693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_data","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:24:31.050291Z","iopub.execute_input":"2021-11-18T05:24:31.051191Z","iopub.status.idle":"2021-11-18T05:24:31.057706Z","shell.execute_reply.started":"2021-11-18T05:24:31.051147Z","shell.execute_reply":"2021-11-18T05:24:31.056962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a model for full model\nfull_model = create_model()","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:25:55.771661Z","iopub.execute_input":"2021-11-18T05:25:55.772228Z","iopub.status.idle":"2021-11-18T05:25:57.722656Z","shell.execute_reply.started":"2021-11-18T05:25:55.77219Z","shell.execute_reply":"2021-11-18T05:25:57.721921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create full model callbacks\nfull_model_tensorboard = create_tensorboard_callback()\n\n# No validation set when traiing on all the data, so we can't monitor validation accuracy\nfull_model_early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"accuracy\",\n                                                            patience = 3)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:30:03.948602Z","iopub.execute_input":"2021-11-18T05:30:03.949539Z","iopub.status.idle":"2021-11-18T05:30:04.33493Z","shell.execute_reply.started":"2021-11-18T05:30:03.9495Z","shell.execute_reply":"2021-11-18T05:30:04.334204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fit the full model to the full data\nfull_model.fit(x= full_data,\n              epochs = NUM_EPOCHS,\n              callbacks = [full_model_tensorboard, full_model_early_stopping])","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:31:23.142982Z","iopub.execute_input":"2021-11-18T05:31:23.143562Z","iopub.status.idle":"2021-11-18T05:42:13.853928Z","shell.execute_reply.started":"2021-11-18T05:31:23.143521Z","shell.execute_reply":"2021-11-18T05:42:13.852849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_model(full_model, suffix =\"full-image-set-mobilenetv2-Adam\")","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:48:44.054273Z","iopub.execute_input":"2021-11-18T05:48:44.054856Z","iopub.status.idle":"2021-11-18T05:48:44.26675Z","shell.execute_reply.started":"2021-11-18T05:48:44.054818Z","shell.execute_reply":"2021-11-18T05:48:44.266081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loaded_full_model =  load_model('models/20211118-05481637214524-full-image-set-mobilenetv2-Adam.h5'\n)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:50:15.207269Z","iopub.execute_input":"2021-11-18T05:50:15.207946Z","iopub.status.idle":"2021-11-18T05:51:14.983745Z","shell.execute_reply.started":"2021-11-18T05:50:15.20791Z","shell.execute_reply":"2021-11-18T05:51:14.982922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(X)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T05:51:40.68742Z","iopub.execute_input":"2021-11-18T05:51:40.688262Z","iopub.status.idle":"2021-11-18T05:51:40.693707Z","shell.execute_reply.started":"2021-11-18T05:51:40.688225Z","shell.execute_reply":"2021-11-18T05:51:40.693014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Making predictions on the test datasets\n\nsince our model has been trained on images in the form of Tensor batches\nto make predictions on the test data, we'll have to get it into the same format.\n\nwe created `create_data_batches()` earlier which can take a list of filenames as input and cover them into Tensor batches.\n\nTo make predictions on the test data we'll:\n* Get the test image filenames\n* Convert the filenames into test data batches `create_data_batches` and setting the `test_data` parameter to `True` (since the test data doesn't have labels).\n* Make a predictions array by passing the test batches to the `predict()` method called on our model.\n","metadata":{}},{"cell_type":"code","source":"# Load test image filenames\ntest_path = ('../input/dog-breed-identification/test/')\n\ntest_filenames = [test_path + fname for fname in os.listdir(test_path)]\ntest_filenames[:10]","metadata":{"execution":{"iopub.status.busy":"2021-11-18T06:44:26.020419Z","iopub.execute_input":"2021-11-18T06:44:26.02074Z","iopub.status.idle":"2021-11-18T06:44:26.049267Z","shell.execute_reply.started":"2021-11-18T06:44:26.020706Z","shell.execute_reply":"2021-11-18T06:44:26.048575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(test_filenames)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T06:44:27.428577Z","iopub.execute_input":"2021-11-18T06:44:27.429108Z","iopub.status.idle":"2021-11-18T06:44:27.434617Z","shell.execute_reply.started":"2021-11-18T06:44:27.429072Z","shell.execute_reply":"2021-11-18T06:44:27.433734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create test data batch\ntest_data = create_data_batches(test_filenames, test_data = True)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T06:44:30.004277Z","iopub.execute_input":"2021-11-18T06:44:30.004863Z","iopub.status.idle":"2021-11-18T06:44:37.304693Z","shell.execute_reply.started":"2021-11-18T06:44:30.004826Z","shell.execute_reply":"2021-11-18T06:44:37.303899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data","metadata":{"execution":{"iopub.status.busy":"2021-11-18T06:44:37.306578Z","iopub.execute_input":"2021-11-18T06:44:37.30698Z","iopub.status.idle":"2021-11-18T06:44:37.312666Z","shell.execute_reply.started":"2021-11-18T06:44:37.306944Z","shell.execute_reply":"2021-11-18T06:44:37.311908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Note:**  Calling `predict()` on our full model and passing it the test data batch will take a long time to run","metadata":{}},{"cell_type":"code","source":"# Make predictions on test data batch using the loaded full model\n\ntest_predictions= loaded_full_model.predict(test_data,verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T06:44:40.393763Z","iopub.execute_input":"2021-11-18T06:44:40.394345Z","iopub.status.idle":"2021-11-18T06:45:21.363134Z","shell.execute_reply.started":"2021-11-18T06:44:40.39429Z","shell.execute_reply":"2021-11-18T06:45:21.362349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save predictions numpy array to csv file for access later\nnp.savetxt(\"preds_array.csv\", test_predictions, delimiter = \",\")","metadata":{"execution":{"iopub.status.busy":"2021-11-18T06:46:00.798818Z","iopub.execute_input":"2021-11-18T06:46:00.799111Z","iopub.status.idle":"2021-11-18T06:46:03.106072Z","shell.execute_reply.started":"2021-11-18T06:46:00.799079Z","shell.execute_reply":"2021-11-18T06:46:03.102744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_predictions = np.loadtxt(\"preds_array.csv\", delimiter = \",\")","metadata":{"execution":{"iopub.status.busy":"2021-11-18T06:47:31.715803Z","iopub.execute_input":"2021-11-18T06:47:31.716086Z","iopub.status.idle":"2021-11-18T06:47:33.122245Z","shell.execute_reply.started":"2021-11-18T06:47:31.716042Z","shell.execute_reply":"2021-11-18T06:47:33.121486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_predictions[:10]","metadata":{"execution":{"iopub.status.busy":"2021-11-18T06:47:33.123827Z","iopub.execute_input":"2021-11-18T06:47:33.124091Z","iopub.status.idle":"2021-11-18T06:47:33.133854Z","shell.execute_reply.started":"2021-11-18T06:47:33.124047Z","shell.execute_reply":"2021-11-18T06:47:33.133018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_predictions.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-18T06:47:54.57291Z","iopub.execute_input":"2021-11-18T06:47:54.573178Z","iopub.status.idle":"2021-11-18T06:47:54.579172Z","shell.execute_reply.started":"2021-11-18T06:47:54.573149Z","shell.execute_reply":"2021-11-18T06:47:54.578444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preparing test dataset predictions for kaggle\n\nTo get the data in this format we'll:\n* create a pandas dataframe with an ID column as well as a column for each dog breed\n* add data to the ID column by extracting the test image ID's from their filepaths.\n* add data the prediction probabilities to each of the dog breed columns\n* Export the dataframe as a csv to submit it to kaggle","metadata":{}},{"cell_type":"code","source":"# Create a panad data with empty columns\npreds_df = pd.DataFrame(columns =['id']+ list(unique_breeds))\n\npreds_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-18T07:02:59.430743Z","iopub.execute_input":"2021-11-18T07:02:59.430998Z","iopub.status.idle":"2021-11-18T07:02:59.450145Z","shell.execute_reply.started":"2021-11-18T07:02:59.43097Z","shell.execute_reply":"2021-11-18T07:02:59.449274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Append test image ID's to prediction dataframe\ntest_ids = [os.path.splitext(path)[0] for path in os.listdir(test_path)]\npreds_df[\"id\"] = test_ids","metadata":{"execution":{"iopub.status.busy":"2021-11-18T07:03:07.745516Z","iopub.execute_input":"2021-11-18T07:03:07.74604Z","iopub.status.idle":"2021-11-18T07:03:07.784769Z","shell.execute_reply.started":"2021-11-18T07:03:07.746005Z","shell.execute_reply":"2021-11-18T07:03:07.784002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-18T07:03:11.924874Z","iopub.execute_input":"2021-11-18T07:03:11.925722Z","iopub.status.idle":"2021-11-18T07:03:11.948826Z","shell.execute_reply.started":"2021-11-18T07:03:11.925672Z","shell.execute_reply":"2021-11-18T07:03:11.948136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add the predicitions probabilities to each log dog breed column\npreds_df[list(unique_breeds)] =  test_predictions\npreds_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-18T07:03:15.084409Z","iopub.execute_input":"2021-11-18T07:03:15.084934Z","iopub.status.idle":"2021-11-18T07:03:15.46452Z","shell.execute_reply.started":"2021-11-18T07:03:15.084897Z","shell.execute_reply":"2021-11-18T07:03:15.46359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save our predicition dataframe to csv\npreds_df.to_csv(\"full_model_prediction_submission_1_mobilenetV2.csv\",\n               index= False)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T07:05:02.063894Z","iopub.execute_input":"2021-11-18T07:05:02.064168Z","iopub.status.idle":"2021-11-18T07:05:04.630725Z","shell.execute_reply.started":"2021-11-18T07:05:02.064138Z","shell.execute_reply":"2021-11-18T07:05:04.629947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}